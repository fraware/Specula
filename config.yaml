# TLAGEN Configuration File
# LLM Model Configuration
llm:
  base_url: "https://yunwu.ai/v1"
  # Model name - please choose a model appropriate for your API access
  model: "claude-opus-4-20250514"  # Options: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
  
  # API Parameters
  max_tokens: 32000        # Maximum output tokens (claude-3-5-sonnet-20241022 has a limit of 8192)
  temperature: 0.1        # Controls randomness of generation, 0.0-1.0, lower is more deterministic
  timeout: 3000           # API request timeout (seconds)
  
  # Streaming Configuration
  use_streaming: true     # Whether to use streaming
  stream_chunk_size: 2000 # Progress display interval for streaming

# TLA+ Validator Configuration
tla_validator:
  tools_path: "lib/tla2tools.jar"  # Path to TLA+ tools
  timeout: 30                      # Validator timeout (seconds)

# Generation Configuration
generation:
  max_correction_attempts: 3  # Maximum error correction attempts
  mode: "draft-based"              # Generation mode: "direct" or "draft-based"
  
# Path Configuration
paths:
  prompts_dir: "src/prompts"
  output_dir: "output"
  
# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "[%(levelname)s] %(message)s" 